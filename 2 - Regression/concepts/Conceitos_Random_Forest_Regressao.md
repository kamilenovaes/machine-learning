# üß† Conceitos: Regress√£o com Random Forest

Este arquivo cont√©m um resumo te√≥rico sobre o algoritmo de Regress√£o com Random Forest.

## üéØ O que √©?

Random Forest √© um algoritmo de **ensemble learning**, o que significa que ele combina m√∫ltiplos modelos para obter uma previs√£o melhor e mais est√°vel. Especificamente, ele constr√≥i **muitas √Årvores de Decis√£o** durante o treinamento.

Para fazer uma previs√£o de regress√£o, cada √°rvore na floresta faz sua pr√≥pria previs√£o individual. A previs√£o final do Random Forest √© a **m√©dia das previs√µes de todas as √°rvores**.

## ü§î A "M√°gica" da Aleatoriedade

O nome "Random Forest" vem de duas fontes de aleatoriedade que o algoritmo usa para evitar o overfitting das √°rvores individuais:

1.  **Amostragem Aleat√≥ria de Dados (Bootstrap):** Cada √°rvore √© treinada em uma amostra aleat√≥ria (com reposi√ß√£o) do conjunto de dados original. Isso significa que cada √°rvore v√™ uma vers√£o ligeiramente diferente dos dados.
2.  **Sele√ß√£o Aleat√≥ria de Features:** Em cada n√≥ da √°rvore, em vez de verificar todas as features para encontrar a melhor divis√£o, o algoritmo seleciona apenas um subconjunto aleat√≥rio de features.

Essa dupla aleatoriedade garante que as √°rvores na floresta sejam bem diferentes umas das outras.

## ‚úÖ Por que usar?

- **Alta Precis√£o:** Geralmente fornece resultados muito precisos e √© um dos algoritmos mais populares.
- **Robusto a Overfitting:** Ao tirar a m√©dia de muitas √°rvores, ele corrige o principal problema de uma √∫nica √°rvore de decis√£o.
- **Import√¢ncia das Features:** Ele consegue nos dizer quais features foram mais importantes para a previs√£o.