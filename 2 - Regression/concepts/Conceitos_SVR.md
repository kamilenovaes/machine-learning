# üß† Conceitos: Support Vector Regression (SVR)

Este arquivo cont√©m um resumo te√≥rico sobre o algoritmo Support Vector Regression (SVR).

## üéØ O que √©?

A SVR √© a vers√£o de regress√£o do famoso algoritmo de classifica√ß√£o **Support Vector Machine (SVM)**. A principal ideia da SVR √© diferente da regress√£o linear tradicional.

Em vez de tentar minimizar o erro entre a previs√£o e todos os pontos de dados, a SVR tenta ajustar a melhor linha (ou hiperplano) que se encaixa no **maior n√∫mero de pontos de dados poss√≠vel DENTRO de uma margem de erro definida**.

Imagine a linha de regress√£o como uma "rua". A SVR n√£o se importa com os pontos que est√£o dentro da rua, apenas com os que est√£o fora. Os pontos que definem os limites dessa rua s√£o chamados de **vetores de suporte**.

## ü§î A Margem de Erro (Epsilon - Œµ)

A SVR tem um hiperpar√¢metro crucial chamado **epsilon (Œµ)**, que define a largura da "rua".
- O modelo s√≥ penaliza os erros para os pontos que caem **fora** dessa margem.
- Isso torna a SVR muito robusta a **outliers**, pois se um outlier estiver dentro da margem, ele ser√° ignorado.


## ‚úÖ Quando usar?

- Funciona bem em datasets com muitas features (alta dimensionalidade).
- √â muito eficaz quando o n√∫mero de features √© maior que o n√∫mero de amostras.
- √â robusto a outliers, gra√ßas ao conceito da margem de erro.